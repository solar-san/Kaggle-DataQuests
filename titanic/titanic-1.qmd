---
title: "Machine Learning from Disaster"
subtitle: "Part 1: Data Exploration and Logit in `R`"
author: "solar-san"
date-modified: "`r Sys.Date()`"
format:
  html:
    theme: github
    toc: true
    toc-location: left
    fig-align: center
    fig-width: 10
    fig-height: 10
    html-math-method: katex
    code-overflow: scroll
    code-copy: hover
    code-fold: show
    highlight-style: arrow
    citations-hover: true
    footnotes-hover: true
    header-includes: |
      <meta name="author" content="solar-san">
      <meta name="image" property="og:image" content="https://github.com/solar-san/Kaggle-DataQuests/blob/main/docs/figures/header.png?raw=true">
      <link rel="preconnect" href="https://fonts.googleapis.com">
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible:ital,wght@0,400;0,700;1,400;1,700&family=Fira+Code&display=swap" rel="stylesheet">
mainfont: "Atkinson Hyperlegible"
monofont: 'Fira Code'
---

![](figures/header.png)
```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE
  )

requirements <- c(
  "MASS",
  "tidyverse",
  "glmnet",
  "ggthemes",
  "patchwork"
)

submission_flag = FALSE

lapply(
  requirements, 
  library, 
  character.only = T)

theme_set(
  theme_tufte(
    base_size = 12,
    base_family = 'Atkinson Hyperlegible',
    ticks = F
    )
  )
```

# Loading data

```{r data loader}
source("helper_functions.R")
```

```{r loading data}
train_data <- data_loader(
  "titanic.zip",
  "train.csv"
)
test_data <- data_loader(
  "titanic.zip",
  "test.csv"
)
```

# Data Exploration

```{r dataset str train}
train_data %>% str

```
```{r dataset str test}
test_data %>% str
```

Some variables might benefit from scaling: `Fare` and `Age`.

```{r scaling data and transforming variables}
train_data <- train_data %>% 
  mutate(
    Age = scale(Age),
    Fare = scale(Fare),
    SibSp = scale(SibSp),
    Parch = scale(Parch),
    Sex = ifelse(
        Sex == "male",
        "Male",
        ifelse(Sex == "female",
               "Female",
               NA
        )
      )
  )
test_data <- test_data %>% 
  mutate(
    Age = scale(Age),
    Fare = scale(Fare),
    SibSp = scale(SibSp),
    Parch = scale(Parch),
    Sex = ifelse(
        Sex == "male",
        "Male",
        "Female"
      )
  )
```

```{r summary descriptive stats of test data}
train_data %>% summary
```

> In the test data we do not have the dependent variable. Therefore, we need to split the dataset and use cross-validation to estimate the error.

```{r creating CV set}
N_train_obs <- dim(train_data)[1]

train_idx <- sample(
  N_train_obs,
  N_train_obs*.5
)
```

# Data transformation: `as.factor`

```{r mutate into factors 1}
factorize_data <- function(dataframe) {
  dataframe %>% 
  select(-Name, -Ticket) %>% 
  mutate(
    Pclass = as.factor(Pclass),
    Sex = as.factor(Sex),
    # SibSp = as.factor(SibSp),
    # Parch = as.factor(Parch),
    Cabin = as.factor(Cabin),
    Embarked = as.factor(Embarked)
  )
}
```

```{r mutate into factors 2}
train_data_factorized <- factorize_data(dataframe = train_data) 
test_data_factorized <- factorize_data(dataframe = test_data)
```

```{r mutate into factors 3}
train_data_factorized %>% summary
```

# Data Visualization

## Quantiles Table

```{r quantiles table 1}
quantiles_table <- train_data %>% 
  factorize_data() %>% 
  group_by(
    Sex,
    Pclass
    ) %>% 
  reframe(
    Age_Quantiles = quantile(
      de_scale(
        Age
        ), 
      probs = c(
        .25, 
        .5, 
        .75
        ), 
      na.rm = T
      ) %>% 
      round(
        .,
        digits = 0
        )
  ) %>% 
  mutate(
    Quantile = rep(
      c(
        .25, 
        .50, 
        .75
        ),
      6
    )
  )
```

```{r quantiles table 2}
quantiles_table
```

## Correlations

```{r corrplot, fig.width=6, fig.height=8, fig.align='center'}
cor_bygender_female <- train_data %>% 
  filter(
    Sex == "Female"
    ) %>% 
  select(
    -PassengerId
  ) %>% 
  GGally::ggcorr(
    method = c(
      "complete.obs",
      "pearson"
    ),
    geom = "text",
    layout.exp = 1,
    nbreaks = 5,
    color = "grey30",
    size = 5,
    family = "Atkinson Hyperlegible",
    legend.position = "top",
    
    ) +
  labs(
    title = "Correlation Matrices"
  ) +
  theme(
    legend.text = element_text(
      size = 14,
      ),
    )

cor_bygender_male <- train_data %>% 
  filter(
    Sex == "Male"
    ) %>% 
  GGally::ggcorr(
    method = c(
      "complete.obs",
      "pearson"
    ),
    geom = "text",
    nbreaks = 5,
    color = "white",
    legend.position = "none"
  )
  

cor_bygender_female / cor_bygender_male
```

## Survivorship | Number of Siblings, Gender, Passenger Class, Age

```{r survivorship barplot, warning=FALSE, fig.width=8, fig.height=10, fig.cap="The mean age is centered at zero."}
train_data %>% 
  factorize_data() %>%
  ggplot(
    aes(
      fill = factor(
        ifelse(
          Survived == 1,
          "Yes",
          "No"
          )
        ),
      x = de_scale(SibSp),
      y = Age/100
    )
  ) +
  geom_bar(
    width = .7,
    stat = "identity"
  ) +
   geom_hline(
    yintercept = mean(
      train_data$Age,
      na.rm = T
      ), col="grey99",
    lwd = 1,
    ) +
  facet_wrap(
    vars(
      Sex,
      ifelse(
        Pclass == 1,
        "First Class",
        ifelse(
          Pclass == 2,
          "Second Class",
          "Third Class"
        )
      )
    )
  ) +
  scale_color_viridis_d(
    aesthetics = c(
      "colour", 
      "fill"),
    option = "A",
    begin = 0,
    end = 0.6
  ) +
  labs(
    title = "Survivorship on the Titanic based on Number of Siblings, Age, Class, and Gender",
    fill = "Survived",
    x = "Number of Siblings",
    y = "Age (Normalized)"
  ) +
  theme_tufte(
    base_size = 16,
    base_family = "Atkinson Hyperlegible"
  ) +
  theme(
    legend.position = "top",
    )
```

```{r boxplots,warning=FALSE, fig.width=10, fig.height=12}
train_data %>% 
  factorize_data() %>%
  mutate(
    Survived = factor(
        ifelse(
          Survived == 1,
          "Yes",
          "No"
          )
        ),
    PClass = ifelse(
        Pclass == 1,
        "First Class",
        ifelse(
          Pclass == 2,
          "Second Class",
          "Third Class"
        )
      )
    ) %>% 
  ggplot(
    aes(
      x = Survived,
      y = Age %>% de_scale()
    )
  ) +
  geom_tufteboxplot(
    median.type = "line",
    whisker.type = "point",
    size = 2,
    na.rm = T
  ) +
  coord_flip() +
  facet_grid(
    vars(
      Sex,
      Pclass)
  ) +
  scale_color_viridis_d(
    aesthetics = c(
      "colour", 
      "fill"),
    option = "A",
    begin = .6,
    end = 0
  ) +
  labs(
    title = "Distributions of Survivorship | Age, Sex, Class",
    y = "Age",
    caption = "On the left side: if the passenger survived. On the left: class (1, 2, 3) and gender."
  ) +
  theme(
    legend.position = "top"
    ) +
  theme_tufte(
    base_size = 18,
    base_family = "Atkinson Hyperlegible"
  )
```

# (Linear) Model selection: Logistic Regression + Stepwise Selection

## Stepwise Selection

```{r logit full fit}
fit_full <- glm(
  Survived ~ ., 
  data = train_data_factorized, 
  family = "binomial",
  na.action = na.omit,
  subset = train_idx
)
```

```{r logit full summary}
fit_full %>% summary
```

```{r logit null fit}
fit_null <- glm(
  Survived ~ 1, 
  data = train_data_factorized, 
  family = "binomial",
  na.action = na.omit,
  subset = train_idx
)
```

```{r stepwise selection}
sel_stepwise <- step(
  fit_full,
  scope = c(fit_null, fit_full),
  direction = "both",
  k = log(
    dim(train_data_factorized)[1]
    )
)
```


```{r stepwise output summary}
sel_stepwise %>% summary()
```

```{r updated model with interaction terms}
sel_stepwise <- update(
  sel_stepwise,
  formula = Survived ~ Pclass*Sex*Age + SibSp,
  subset = train_idx
)
sel_stepwise %>% summary()
```

## Interpreting the Coefficients

```{r converting coefficients}
convert_to_prob <- function(logit) {
  exp(logit)/(1+exp(logit))
}
```


```{r showing converted coefficients}
sel_stepwise %>% coef() %>% convert_to_prob()
```

## Make Predictions and Fine-Tuning

### Predictions

```{r computing predictions and ROC}
predictions <- 
  ifelse(
  predict(
    sel_stepwise,
    newdata = train_data_factorized[-train_idx, ],
    type = "response"
  ) > 0.7293,
  1,
  0
)

pROC::roc(
  train_data_factorized[-train_idx, ]$Survived,
  predictions,
)
```

```{r visualizing ROC}
pROC::ggroc(
  pROC::roc(
  train_data_factorized[-train_idx, ]$Survived,
  predictions,
  )
) +
  geom_abline(
    aes(
      slope = 1,
      intercept = 1
    ),
    color = "grey90"
  )
```
### Error Estimation

```{r estimating error}
mean(predictions == train_data_factorized[-train_idx, ]$Survived, na.rm = TRUE )
```

## Creating submission `csv`

```{r use test data prediction}
predictions_test <- ifelse(
  predict(
    sel_stepwise,
    newdata = test_data_factorized,
    type = "response"
  ) > 0.7293,
  1,
  0
)
```


```{r creating new submission dataframe}
if(submission_flag == T) {
  submission <- data.frame(
    PassengerId = test_data %>%
      select(PassengerId),
    Survived = predictions_test
  )
  submission %>% head
}
```

```{r write csv for kaggle submission}
if(submission_flag == T) {
  write.csv(
    submission,
    "data/submission.csv",
    row.names = FALSE
  )
}
```

## Submission results

> ___Score___: 0.6244

This result is awful: as expected, the _logistic regression_ is highly interpretable but suffers from high bias and therefore has low prediction capabilities.